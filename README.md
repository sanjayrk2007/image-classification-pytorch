# ğŸ§  Image Classification: CNN & ResNet on CIFAR-10

> **PyTorch** Â· Custom CNN from scratch Â· ResNet18 transfer learning Â· **~90%+ accuracy**

Two approaches to the same goal: train and compare a **hand-built CNN** and a **pretrained ResNet** on CIFAR-10. Built for portfolio showcase and quick revision of CNN & image classification.

---

## â–¶ What's in this repo

| | **Custom CNN** | **ResNet18** |
|--|----------------|--------------|
| **Approach** | Built from scratch | Pretrained, fine-tuned |
| **Accuracy** | **89.11%** | **91.95%** |
| **Epochs** | 30 | 10 |
| **Notebook** | `cnn_pytorch.ipynb` | `resnet_pytorch.ipynb` |

---

## ğŸ“¦ Dataset: CIFAR-10

60K colour images (32Ã—32), 10 classes â€” *airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck*.  
50K train / 10K test, balanced. Auto-downloads via `torchvision`.

---

## ğŸ— Model architectures (at a glance)

**CNN** â€” Conv blocks (3â†’64â†’128â†’256) with BatchNorm, ReLU, MaxPool â†’ Flatten â†’ FC(512) + Dropout(0.5) â†’ 10 classes. Classic *conv feature extraction + classifier*.

**ResNet** â€” Skip connections: output = `F(x) + x` so gradients flow through identity; enables deep nets. We use **ResNet18** (ImageNet-pretrained), replace the final FC with 10 classes, freeze all except **layer4** and **fc**, then fine-tune. Inputs resized to 224Ã—224 + ImageNet normalization.

---

## ğŸ”„ Data augmentation

**CNN:** `RandomCrop(32, padding=4)` Â· `RandomHorizontalFlip()` Â· `ColorJitter(brightness=0.2, contrast=0.2)` Â· Normalize(0.5, 0.5)  
**ResNet:** `Resize(224,224)` Â· `RandomHorizontalFlip()` Â· ImageNet normalize  

Test/val: no randomness â€” only resize (ResNet) and same normalization.

---

## ğŸ“ˆ Training & evaluation

**Pipeline:** Load CIFAR-10 â†’ model to device â†’ CrossEntropyLoss + Adam â†’ train loop (forward, backward, step) â†’ eval on test/val â†’ save best checkpoint.

| | CNN | ResNet |
|--|-----|--------|
| Optimizer | Adam, lr=0.001 | Adam, lr=1e-4 (unfrozen only) |
| Scheduler | StepLR (Ã—0.5 every 10 epochs) | â€” |
| Metric | Validation accuracy | Test accuracy |
| Checkpoint | `best_model.pth` | â€” |

---

## ğŸš€ Run it

**Requirements:** Python 3.7+, PyTorch, torchvision. (GPU optional but faster.)

```bash
pip install -r requirements.txt
```

Then open and run **all cells** in `cnn_pytorch.ipynb` and/or `resnet_pytorch.ipynb`. Data goes to `./data` on first run.

---

## ğŸ“ Project layout

```
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ cnn_pytorch.ipynb      # CNN from scratch
â”œâ”€â”€ resnet_pytorch.ipynb   # ResNet18 transfer learning
â”œâ”€â”€ data/                  # CIFAR-10 (auto-created)
â””â”€â”€ best_model.pth         # Best CNN weights (after training)
```

---

## ğŸ’¡ Concepts covered

CNNs (conv, padding, pooling) Â· BatchNorm Â· Residual connections Â· Transfer learning & fine-tuning Â· Data augmentation Â· Train/eval loop Â· LR scheduling Â· Checkpointing

---

## ğŸ”® Possible next steps

Deeper/wider CNN Â· CutOut / RandomRotation Â· Unfreeze more ResNet layers Â· Confusion matrix & per-class metrics Â· TensorBoard Â· Reproducibility seeds Â· Standalone inference script

---

*CIFAR-10 citation recommended when using the dataset. PyTorch/torchvision under their respective licenses.*
